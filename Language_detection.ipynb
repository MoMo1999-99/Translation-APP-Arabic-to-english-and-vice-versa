{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ecc5162",
   "metadata": {},
   "source": [
    "## NAME : Mohamed Mousa\n",
    "\n",
    "## Language Detection Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75938ef4",
   "metadata": {},
   "source": [
    "### importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6361269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stemmer = WordNetLemmatizer()\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172da5d7",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15039c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Language_det_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff4327b",
   "metadata": {},
   "source": [
    "### Cleaning Text from any (special characters ,the symbols , numbers , ...........)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef1d30c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "def clean_txt(x):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(x))\n",
    "    # removing the symbols and numbers\n",
    "    document = re.sub(r'[!@#$(),n\"%^*?:;~`0-9]', ' ', document)\n",
    "    document = re.sub(r'[[]]', ' ', document)\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa7c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loop on text data to clean by apply & lambda Func\n",
    "data['Text'] = data['Text'].apply(lambda x:clean_txt(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6f7c4",
   "metadata": {},
   "source": [
    "### spliting data to Input & target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5134e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Text']\n",
    "y = data['Language']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eccfc39",
   "metadata": {},
   "source": [
    "### spliting data to train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5659ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72 , stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ec8fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label encoding for Y target to  transform categorical labels into numerical values \n",
    "### By assigning a unique numerical identifier to each category\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train) \n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab821108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize TF-IDF vectorization to convert text data into numerical representations.\n",
    "# This technique captures the importance of words in distinguishing between different languages\n",
    "###    , enhancing the model's language detection capabilities.\n",
    "\n",
    "\n",
    "# Initialize TF-IDF vectorizer with character-level analysis and n-gram range of 1 to 3.\n",
    "tfidfvectorizer = TfidfVectorizer( analyzer='char' , ngram_range=(1,3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23a67f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline to streamline the text processing and classification workflow.\n",
    "# The 'TF-idf' step uses the TF-IDF vectorizer initialized earlier to convert text data into numerical representations.\n",
    "# The 'LR' step utilizes Logistic Regression as the classification algorithm to predict the language of the input text.\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('TF-idf', tfidfvectorizer),  \n",
    "    ('LR', LogisticRegression())    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cdf2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019849a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09c472e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;TF-idf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 3))),\n",
       "                (&#x27;LR&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;TF-idf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 3))),\n",
       "                (&#x27;LR&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('TF-idf',\n",
       "                 TfidfVectorizer(analyzer='char', ngram_range=(1, 3))),\n",
       "                ('LR', LogisticRegression())])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline to the training data, X_train and y_train_encoded.\n",
    "# This step trains the TF-IDF vectorizer on the training text data and then fits the Logistic Regression classifier to learn the language patterns.\n",
    "# Once trained, the pipeline is capable of transforming and classifying new text data.\n",
    "# Predict the language labels for the test data, X_test, using the trained pipeline.\n",
    "# The predicted labels are stored in y_pred for further evaluation of the model's performance.\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train_encoded)\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ccf58",
   "metadata": {},
   "source": [
    "- Calculate precision, recall, and accuracy to evaluate the language detection model.\n",
    "- Precision measures the accuracy of positive predictions, while recall assesses the model's ability to capture all instances of each language.\n",
    "- These metrics are valuable even in balanced datasets, providing insights into the model's performance across all languages.\n",
    "- Accuracy provides an overall measure of correctness, complementing precision and recall in evaluating model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "300f661b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9831975560081466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       102\n",
      "           1       0.95      0.93      0.94        81\n",
      "           2       0.95      0.99      0.97       104\n",
      "           3       0.98      0.99      0.98       263\n",
      "           4       0.98      0.99      0.99       193\n",
      "           5       0.99      0.96      0.97        89\n",
      "           6       1.00      1.00      1.00        69\n",
      "           7       1.00      1.00      1.00        12\n",
      "           8       0.99      0.98      0.98       133\n",
      "           9       1.00      1.00      1.00        70\n",
      "          10       1.00      1.00      1.00       113\n",
      "          11       0.98      0.96      0.97       140\n",
      "          12       1.00      0.99      1.00       132\n",
      "          13       0.97      0.98      0.97       156\n",
      "          14       0.98      0.96      0.97       128\n",
      "          15       1.00      1.00      1.00        89\n",
      "          16       0.99      1.00      0.99        90\n",
      "\n",
      "    accuracy                           0.98      1964\n",
      "   macro avg       0.99      0.98      0.98      1964\n",
      "weighted avg       0.98      0.98      0.98      1964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test_encoded, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fb93736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;TF-idf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 3))),\n",
       "                (&#x27;LR&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;TF-idf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 3))),\n",
       "                (&#x27;LR&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('TF-idf',\n",
       "                 TfidfVectorizer(analyzer='char', ngram_range=(1, 3))),\n",
       "                ('LR', LogisticRegression())])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0a036a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Save the pipeline to a file\n",
    "joblib.dump(pipeline, 'language_detection_pipeline.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "855f1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pipeline = joblib.load('language_detection_pipeline.pkl')\n",
    "\n",
    "# Use the loaded pipeline for predictions\n",
    "loaded_predictions = loaded_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91853244",
   "metadata": {},
   "source": [
    "### Testing Model in a Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07280b88",
   "metadata": {},
   "source": [
    "- language detection model can classify more than minimum languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c5c08f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for prediction: 0.026526689529418945 seconds\n",
      "['Portugeese']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "TextData = 'it was disco ti ued i february'\n",
    "arabic_Text = ' عزا فريق في مركز بالو ألتو للأبحاث هذا التباطؤ في النمو إلى التفرد المتزايد للمشروع ومقاومته للتغيير '\n",
    "portugeese_text =  'a wikipédia recebe e tre e pedidos de pági a por segu do depe de do da hora do dia ' \n",
    "\n",
    "\n",
    "# Clean text input\n",
    "cleaned_text = clean_txt(portugeese_text)\n",
    "start_time = time.time()\n",
    "# Make prediction using the loaded pipeline\n",
    "predicted_language_encoded = pipeline.predict([cleaned_text])[0]\n",
    "end_time = time.time()\n",
    "# Inverse transform the predicted label\n",
    "predicted_language = label_encoder.inverse_transform([predicted_language_encoded])\n",
    "\n",
    "# Calculate the time taken for prediction\n",
    "prediction_time = end_time - start_time\n",
    "print(\"Time taken for prediction:\", prediction_time, \"seconds\")\n",
    "print(predicted_language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e1cc49",
   "metadata": {},
   "source": [
    "### Building app.py file for creating Apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d167ff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import uvicorn\n",
    "import joblib\n",
    "from fastapi import FastAPI ,HTTPException\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import re\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, AdamWeightDecay, TFAutoModelForSeq2SeqLM\n",
    "\n",
    "pipeline = joblib.load('language_detection_pipeline.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "\n",
    "model_eng2ar = TFAutoModelForSeq2SeqLM.from_pretrained(\"D:\\Kemet NLP\\en2ar_model\")\n",
    "tokenizer_eng2ar = AutoTokenizer.from_pretrained(\"D:\\Kemet NLP\\en2ar_tok\")\n",
    " \n",
    "model_ar2eng = TFAutoModelForSeq2SeqLM.from_pretrained(\"D:\\Kemet NLP\\ar2eng_model\")\n",
    "tokenizer_ar2eng =AutoTokenizer.from_pretrained(\"D:\\Kemet NLP\\ar2eng_model_tok\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict_pipeline(text):\n",
    "    # Remove all the special characters\n",
    "    text = re.sub(r'\\W', ' ', str(text))\n",
    "    # removing the symbols and numbers\n",
    "    text = re.sub(r'[!@#$(),n\"%^*?:;~`0-9]', ' ', text)\n",
    "    text = re.sub(r'\\[\\]', ' ', text)\n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    # Removing prefixed 'b'\n",
    "    text = re.sub(r'^b\\s+', '', text)\n",
    "    # Converting to Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    predicted_language_encoded = pipeline.predict([text])[0]\n",
    "    \n",
    "    return predicted_language_encoded\n",
    "\n",
    "def translate_eng2ar(clean_text):\n",
    "    input_text =  clean_text\n",
    "    inputs = tokenizer_eng2ar(input_text, return_tensors=\"pt\").input_ids\n",
    "    outputs = model_eng2ar.generate(inputs, max_length=64)\n",
    "    translated_text = tokenizer_eng2ar.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return translated_text\n",
    "\n",
    "def translate_ar2eng(clean_text):\n",
    "    input_text =  clean_text\n",
    "    inputs = tokenizer_ar2eng(input_text, return_tensors=\"pt\").input_ids\n",
    "    outputs = model_ar2eng.generate(inputs, max_length=64)\n",
    "    translated_text = tokenizer_ar2eng.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return translated_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TextIn(BaseModel):\n",
    "    TextIn: str\n",
    "\n",
    "class PredictionOut(BaseModel):\n",
    "    language: str\n",
    "        \n",
    "class Translation(BaseModel):\n",
    "    language: str        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.get(\"/\")\n",
    "def home():\n",
    "    return {\"health_check\": \"OK\"}\n",
    "\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictionOut)\n",
    "def predict_language(payload: TextIn):\n",
    "    try:\n",
    "        if not payload.TextIn.strip():\n",
    "            raise HTTPException(status_code=400, detail=\"Empty text provided\")\n",
    "        \n",
    "        predicted_language_encoded = predict_pipeline(payload.TextIn)\n",
    "        predicted_language = label_encoder.inverse_transform([predicted_language_encoded])[0]\n",
    "        predicted_language_str = str(predicted_language)  # Convert to string if necessary\n",
    "        \n",
    "        return {\"language\": predicted_language_str}\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Log the error\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        # Return an error response\n",
    "        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n",
    "\n",
    "        \n",
    "@app.post(\"/translation/\" , response_model=Translation)\n",
    "async def translate_text(text_data: TextIn):\n",
    "    try:\n",
    "        clean_text = text_data.TextIn.strip()\n",
    "        if not clean_text:\n",
    "            raise HTTPException(status_code=400, detail=\"Empty text provided\")\n",
    "        \n",
    "        predicted_language_encoded = predict_pipeline(clean_text)\n",
    "        predicted_language = label_encoder.inverse_transform([predicted_language_encoded])[0]\n",
    "        predicted_language_str = str(predicted_language)\n",
    "        \n",
    "        if predicted_language_str == 'English':\n",
    "            translated_text = translate_eng2ar(clean_text)\n",
    "        elif predicted_language_str == 'Arabic':\n",
    "            translated_text = translate_ar2eng(clean_text)\n",
    "        else:\n",
    "            raise HTTPException(status_code=400, detail=\"Unsupported language. Only Arabic and English are supported.\")\n",
    "        \n",
    "        return {\"translation\": translated_text}  # Return only the translated text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3862f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f426e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d18ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
